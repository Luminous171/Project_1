{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nika's notebook\n",
    "\n",
    "# Import statements\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state_id</th>\n",
       "      <th>state_name</th>\n",
       "      <th>county_fips</th>\n",
       "      <th>county_name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>population</th>\n",
       "      <th>density</th>\n",
       "      <th>ranking</th>\n",
       "      <th>id</th>\n",
       "      <th>firstzip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>36061</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.6943</td>\n",
       "      <td>-73.9249</td>\n",
       "      <td>18713220.0</td>\n",
       "      <td>10715.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1840034016</td>\n",
       "      <td>11229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>6037</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>34.1139</td>\n",
       "      <td>-118.4068</td>\n",
       "      <td>12750807.0</td>\n",
       "      <td>3276.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1840020491</td>\n",
       "      <td>90291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>17031</td>\n",
       "      <td>Cook</td>\n",
       "      <td>41.8373</td>\n",
       "      <td>-87.6862</td>\n",
       "      <td>8604203.0</td>\n",
       "      <td>4574.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1840000494</td>\n",
       "      <td>60018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miami</td>\n",
       "      <td>FL</td>\n",
       "      <td>Florida</td>\n",
       "      <td>12086</td>\n",
       "      <td>Miami-Dade</td>\n",
       "      <td>25.7839</td>\n",
       "      <td>-80.2102</td>\n",
       "      <td>6445545.0</td>\n",
       "      <td>5019.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1840015149</td>\n",
       "      <td>33129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "      <td>Texas</td>\n",
       "      <td>48113</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>32.7936</td>\n",
       "      <td>-96.7662</td>\n",
       "      <td>5743938.0</td>\n",
       "      <td>1526.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1840019440</td>\n",
       "      <td>75287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29483</th>\n",
       "      <td>Caputa</td>\n",
       "      <td>SD</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>46103</td>\n",
       "      <td>Pennington</td>\n",
       "      <td>43.9960</td>\n",
       "      <td>-102.9847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1840035951</td>\n",
       "      <td>57703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29484</th>\n",
       "      <td>Hamill</td>\n",
       "      <td>SD</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>46123</td>\n",
       "      <td>Tripp</td>\n",
       "      <td>43.5939</td>\n",
       "      <td>-99.6907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1840004186</td>\n",
       "      <td>57534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29485</th>\n",
       "      <td>Loomis</td>\n",
       "      <td>SD</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>46035</td>\n",
       "      <td>Davison</td>\n",
       "      <td>43.7931</td>\n",
       "      <td>-98.1036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1840004170</td>\n",
       "      <td>57301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29486</th>\n",
       "      <td>Bijou Hills</td>\n",
       "      <td>SD</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>46015</td>\n",
       "      <td>Brule</td>\n",
       "      <td>43.5285</td>\n",
       "      <td>-99.1439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1840024011</td>\n",
       "      <td>57369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29487</th>\n",
       "      <td>Ola</td>\n",
       "      <td>SD</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>46015</td>\n",
       "      <td>Brule</td>\n",
       "      <td>43.6005</td>\n",
       "      <td>-99.2114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1840024012</td>\n",
       "      <td>57325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29488 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              city state_id    state_name  county_fips  county_name      lat  \\\n",
       "0         New York       NY      New York        36061     New York  40.6943   \n",
       "1      Los Angeles       CA    California         6037  Los Angeles  34.1139   \n",
       "2          Chicago       IL      Illinois        17031         Cook  41.8373   \n",
       "3            Miami       FL       Florida        12086   Miami-Dade  25.7839   \n",
       "4           Dallas       TX         Texas        48113       Dallas  32.7936   \n",
       "...            ...      ...           ...          ...          ...      ...   \n",
       "29483       Caputa       SD  South Dakota        46103   Pennington  43.9960   \n",
       "29484       Hamill       SD  South Dakota        46123        Tripp  43.5939   \n",
       "29485       Loomis       SD  South Dakota        46035      Davison  43.7931   \n",
       "29486  Bijou Hills       SD  South Dakota        46015        Brule  43.5285   \n",
       "29487          Ola       SD  South Dakota        46015        Brule  43.6005   \n",
       "\n",
       "            lng  population  density  ranking          id firstzip  \n",
       "0      -73.9249  18713220.0  10715.0        1  1840034016    11229  \n",
       "1     -118.4068  12750807.0   3276.0        1  1840020491    90291  \n",
       "2      -87.6862   8604203.0   4574.0        1  1840000494    60018  \n",
       "3      -80.2102   6445545.0   5019.0        1  1840015149    33129  \n",
       "4      -96.7662   5743938.0   1526.0        1  1840019440    75287  \n",
       "...         ...         ...      ...      ...         ...      ...  \n",
       "29483 -102.9847         0.0      0.0        3  1840035951    57703  \n",
       "29484  -99.6907         0.0      0.0        3  1840004186    57534  \n",
       "29485  -98.1036         0.0      0.0        3  1840004170    57301  \n",
       "29486  -99.1439         0.0      0.0        3  1840024011    57369  \n",
       "29487  -99.2114         0.0      0.0        3  1840024012    57325  \n",
       "\n",
       "[29488 rows x 12 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the uscities csv. this file will be used for the longitude and latitude, as well as the density stats.\n",
    "longlatdensity_csv = Path(\"../Data/uscities.csv\")\n",
    "longlatdensity_df = pd.read_csv(longlatdensity_csv)\n",
    "longlatdensity_df.head(5)\n",
    "\n",
    "#getting first zipcode from list of zipcodes\n",
    "longlatdensity_df[['firstzip']] = longlatdensity_df['zips'].str.split(\",\", n = 1, expand=True)\n",
    "longlatdensity_df[['firstzip']] = longlatdensity_df['zips'].str[:5]\n",
    "\n",
    "#dropping unnecessary columns\n",
    "longlatdensity_df.drop(columns=['source','military','incorporated','timezone','city_ascii',\"zips\"],inplace=True)\n",
    "longlatdensity_df.drop_duplicates()\n",
    "longlatdensity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Label</th>\n",
       "      <th>Median income (dollars)</th>\n",
       "      <th>Mean income (dollars)</th>\n",
       "      <th>Primary MSA</th>\n",
       "      <th>Secondary MSA</th>\n",
       "      <th>Primary State</th>\n",
       "      <th>Secondary State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61,026</td>\n",
       "      <td>77,948</td>\n",
       "      <td>Aberdeen</td>\n",
       "      <td>None</td>\n",
       "      <td>WA</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>54,808</td>\n",
       "      <td>71,517</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>None</td>\n",
       "      <td>TX</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>53,865</td>\n",
       "      <td>69,443</td>\n",
       "      <td>Adrian</td>\n",
       "      <td>None</td>\n",
       "      <td>MI</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>16,311</td>\n",
       "      <td>25,781</td>\n",
       "      <td>Aguadilla</td>\n",
       "      <td>Isabela</td>\n",
       "      <td>PR</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>57,158</td>\n",
       "      <td>80,800</td>\n",
       "      <td>Akron</td>\n",
       "      <td>None</td>\n",
       "      <td>OH</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Label Median income (dollars) Mean income (dollars) Primary MSA Secondary MSA  \\\n",
       "0                      61,026                77,948    Aberdeen          None   \n",
       "8                      54,808                71,517     Abilene          None   \n",
       "16                     53,865                69,443      Adrian          None   \n",
       "24                     16,311                25,781   Aguadilla       Isabela   \n",
       "32                     57,158                80,800       Akron          None   \n",
       "\n",
       "Label Primary State Secondary State  \n",
       "0                WA            None  \n",
       "8                TX            None  \n",
       "16               MI            None  \n",
       "24               PR            None  \n",
       "32               OH            None  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using median income CSV files from EH notebook\n",
    "\n",
    "median_income_csv = Path(\"../Data/household_income_msa_2019.csv\")\n",
    "median_income_df = pd.read_csv(median_income_csv)\n",
    "median_income_df = median_income_df.transpose() # Transpose the column/headers\n",
    "new_header = median_income_df.iloc[0] #grab the first row for the header\n",
    "median_income_df = median_income_df[1:] #take the data less the header row\n",
    "median_income_df.columns = new_header #set the header row as the df header\n",
    "median_income_df = median_income_df[['Median income (dollars)','Mean income (dollars)']] # Use only median and mean income data columns\n",
    "median_income_df.reset_index(inplace=True)\n",
    "median_income_df[['MSA','extra']] = median_income_df['index'].str.split(\",\", n = 1, expand=True) # Split MSA from text string\n",
    "median_income_df[['State','extra2']] = median_income_df['extra'].str.split(n = 1, expand=True) # Split State from remaining text string\n",
    "median_income_df[['Primary MSA','Secondary MSA']] = median_income_df['MSA'].str.split(\"-\", n = 1, expand=True) # Split Primary MSA from first text string\n",
    "median_income_df[['Primary State','Secondary State']] = median_income_df['State'].str.split(\"-\", n = 1, expand=True) # Split Primary MSA from first text string\n",
    "median_income_df.drop(columns=['index','extra','extra2','MSA','State'],inplace=True) # Drop unnecessary columns\n",
    "median_income_df.drop_duplicates(subset=['Primary MSA','Primary State'], inplace=True) # Drop duplicates -- first instance is the median and mean income by MSA\n",
    "median_income_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating median income df with longlat density based on primary MSA\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
